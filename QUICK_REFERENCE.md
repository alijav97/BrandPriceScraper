# ğŸš€ QUICK REFERENCE CARD

## âš¡ Essential Commands

### Run the App
```bash
streamlit run app.py
```
ğŸ“ Access at: `http://localhost:8501`

### Run Tests
```bash
python test_components.py
```

### Install Dependencies
```bash
pip install -r requirements.txt
```

### Activate Virtual Environment
```bash
# Windows
.\venv\Scripts\activate

# Mac/Linux
source venv/bin/activate
```

---

## ğŸ“ Key Files Reference

| File | Purpose |
|------|---------|
| `app.py` | Main Streamlit application |
| `src/scraper.py` | Web scraping logic |
| `utils/processor.py` | Data processing |
| `config/settings.py` | Configuration settings |
| `requirements.txt` | Dependencies list |
| `README.md` | Full documentation |

---

## ğŸŒ Supported Sites

- âœ… Amazon (US, UK, Germany)
- âœ… eBay
- âœ… MercadoLibre  
- âœ… Alibaba

### Add New Site
1. Edit `config/settings.py` - add site config
2. Edit `src/scraper.py` - add scraper method
3. Call method in `scrape_multiple_sites()`

---

## ğŸ’° Currencies

USD, EUR, GBP, CNY, ARS, JPY, INR

---

## ğŸ“¤ Deploy to Cloud

### GitHub Steps
```bash
git init
git add .
git commit -m "Initial commit"
git branch -M main
git remote add origin <repo-url>
git push -u origin main
```

### Streamlit Cloud
1. Go to https://share.streamlit.io
2. Click "New app"
3. Select repository and `app.py`
4. Click "Deploy"

---

## âš™ï¸ Configuration

File: `config/settings.py`

Key Settings:
- `WEBSITES` - Sites to scrape
- `TIMEOUT` - Request timeout
- `MAX_PRODUCTS_PER_SITE` - Products per site
- `CACHE_DURATION` - Cache expiry

---

## ğŸ› Troubleshooting

### App won't run
â†’ Check venv is activated: `(venv)` should appear
â†’ Verify dependencies: `pip install -r requirements.txt`

### No results
â†’ Check internet connection
â†’ Try different brand name
â†’ Website structure may have changed

### Import errors
â†’ Ensure virtual environment is active
â†’ Run: `pip install -r requirements.txt`

---

## ğŸ“š Documentation Files

- `README.md` - Full guide
- `QUICKSTART.md` - Fast setup
- `CHECKLIST.md` - Complete checklist
- `SETUP_COMPLETE.md` - Setup summary
- `PROJECT_SUMMARY.txt` - This summary

---

## ğŸ¯ Usage Flow

```
User Input Brand Name
         â†“
   Run Scraper
         â†“
   Process Data
         â†“
   Display Results
         â†“
Export to CSV (optional)
```

---

## ğŸ“Š Data Processing

Features:
- Price formatting with currency
- Discount calculation
- Duplicate removal
- Filtering & sorting
- CSV export

---

## ğŸ”’ Scraping Ethics

âœ“ Respect `robots.txt`
âœ“ Don't spam requests (delays included)
âœ“ Check Terms of Service
âœ“ Follow GDPR/CCPA
âœ“ Be responsible with servers

---

## ğŸ“ Quick Help

**Virtual Environment Issues?**
```bash
python -m venv venv
```

**Reinstall Dependencies?**
```bash
pip install -r requirements.txt --force-reinstall
```

**Check What's Installed?**
```bash
pip list
```

**Clear Cache?**
```bash
rm -rf __pycache__ .streamlit/cache
```

---

## ğŸŒŸ Project Structure

```
App for self/
â”œâ”€â”€ app.py              â† Run this!
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ src/
â”‚   â””â”€â”€ scraper.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ processor.py
â””â”€â”€ data/
```

---

## ğŸ“ Learning Path

1. âœ… Basic setup (done)
2. â¬œ Run app locally
3. â¬œ Add more sites
4. â¬œ Deploy to cloud
5. â¬œ Add database
6. â¬œ Create API
7. â¬œ Build mobile app

---

## ğŸ’¡ Pro Tips

- Use `.gitignore` before pushing to GitHub
- Keep `venv/` out of version control
- Test with `test_components.py`
- Monitor requests - use delays
- Update scrapers when sites change HTML

---

**Created:** December 25, 2025
**Status:** âœ… Complete & Ready
**Version:** 1.0
